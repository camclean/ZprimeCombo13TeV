.. _intro:

************
Introduction
************


theta architecture
==================

``theta`` consists of several components, some of which can be used independently. The most important core component is the
:program:`theta` main program, written in C++. It implements the actual statistical methods, the model, etc. but lacks
higher-level functions to display and interpret the result. Such functions are implemented in a set of python script
called *theta-auto*.

Consequently, ``theta`` can be used in different ways, or different *layers*:
 #. The *plugin layer*: extending the theta functionality with plugins -- such as adding new template morphing implementation, or adding new statistical methods
 #. The *cfg-file layer*: the main theta program written in C++ operates on text-based configuration files which specify the statistical model and the statistical methods to run. The configuration file format is relatively simple, but the configuration tends to becomes very large for more complex models.
 #. The *theta-auto layer*: `theta-auto` is a set of python scripts which automatize the task of creating the configuration files for the *cfg-file layer* and also collect and display the result.

In the order the layers were listed, the power and flexibility in general decreases, but the usability increases. 
For most users, *theta-auto* is best suited, and it is recommended that new users start with *theta-auto*.

The documentation on these pages only refer to *theta-auto*. See :ref:`doc_overview` for other sources of documentation, which cover
the other layers.


First example
=============

Look at the file "utils2/examples/counting/analysis.py". You should see::

  model = test_model.simple_counting(s = 1.0, n_obs = 10.0, b = 5.0, b_uncertainty = 3.0)
  model_summary(model)
  result = mle(model, input = 'data', n = 1)
  print "result: ", result
  report.write_html('htmlout')

This analysis.py file defines which steps to perform. Usually, these steps are:

1. define the statistical model. In this example, the model is a counting experiment, generated by a method usually used for unit testing. In more realistic examples, you would
   use ``build_model_from_rootfile`` or ``higgs_datacard.build_model``. In this example, the model has one channel with one bin (i.e., a counting experiment) with a signal level of 1.0, 10.0
   observed events, and a background of 5.0 +- 3.0.
2. generate a model summary with ``model_summary(model)``; we ignore the return value of ``model_summary`` here, as a lot of info is written to the ``report`` object (see below)
3. run the statistical method(s). In this case, a maximum likelihood fit (``mle``) is performed
4. do something with the result of the statistical method, e.g., you could use the result from the mle in another method
5. write the report as html to an output directory

To execute the script above, open a shell, change to the "utils2/examples/counting" directory and execute::

   > ../../theta-auto.py
   
theta-auto will print some informational output (to understand in more detail what is going on behind the scenes, see "Distributed Running" below), execute the
analysis.py script which also evaluates the print statement. The print statement will lead to an output like this::

 result:  {'s': {'bunc': [(-1.2292462791622024e-06, 0.99929568508451982)], '__nll': [-13.02585092993951], 'beta_signal': [(5.0000056392877221, 4.2902356062123381)]}}

In general, the return value you get depends on the method called, but it has often a similar structure: it is a nested dictionary
where the first-level key is the signal process group id (here: 's'; see
"Specifying what is 'signal'" below for the definition of signal process group id). The second-level key identifies some aspect of the result, in this case
all model parameters, and the negative-log-likelihood ("nll") which uses a double underscore prefix for easier filtering between parameter names and other results.
The two parameters in this model are 'bunc' which parameterized the (log-normal) background uncertainty and the signal strength parameter 'beta_signal'.
The value in the dictionary for these keys is a list of results of length ``n = 1``. In case of the ``mle`` method,
each entry in the list is a two-tuple of the maximum likelihood fit and the uncertainty, as returned by the fitter.

You will also see that the directory ``htmlout`` has been created. You can point your browser to ``htmlout/index.html`` to get a summary of the model, including
a list of channels, nuisance parameters, the processes in each channel, the yield impact of the nuisance parameters on the processes, etc.

.. _model_intro:

The Statistical Model
=====================

The statistical model in theta-auto is a model with multiple channels (also called "observables") where
in each channel c, the model is is binned. For each bin i, data follows a Poisson distribution around the expected Poisson mean
λ_ci. This expected yield is given by the sum over all considered background processes and the signal. The signal is scaled
with a "signal strength modifier" ``beta_signal``,

.. math::
  
  \lambda_{c,i}(\beta_{\text{signal}}) = \beta_{\text{signal}} S_{c,i} + \sum_{p} B_{c,p,i}.

Here, c denotes the channel, i is the bin index in this channel and p runs over all background processes.
*S_c* denotes the signal template, scaled to an arbitrary cross section (usually a theory prediction, if available)
and B_cp denotes the template for the background prediction
in channel c of process p which should be scaled to the cross section and luminosity of the analyzed dataset.

The presence of systematic uncertainties affects the yields *λ_ci*. For each
independent source of systematic uncertainty, a nuisance parameter is introduced.
A background normalization uncertainty is modeled with a coefficient for the template B_cp with a log-normal prior.
A shape uncertainty is modeled by choosing a Gaussian prior for the nuisance parameter and using this parameter to interpolate
between the "nominal" template (which is not affected by the uncertainty)
and the shifted templates which are obtained by applying plus/minus "1sigma" systematic shifts to the simulated samples and re-deriving the templates.
This interpolation uses a smooth function which is cubic in the range up to 1sigma and a linear extrapolation beyond 1sigma.

In some cases, it makes sense to split the signal process into several sub-processes which are considered as sum as signal (the main reason is if
these components are affected by different systematic uncertainties). In this case, there are several signal templates *S_c* which are all
scaled by ``beta_signal``. In theta-auto, the word "process" denotes always a single template. If several 
signal process templates should be considered together as "signal" as just described, these are called the "signal process group". More about
the details of the technical representation of signal process groups in theta-auto, see :ref:`what_is_signal`.

Calling the nuisance parameters *θ*, the prediction can now be written as

.. math::
  
  \lambda_{c,i}(\beta_{\text{signal}}, \theta) = \beta_{\text{signal}} \cdot \left(\sum_{s} S_{s,c,i}(\theta)\right) + \sum_{p} c_{c,p}(\theta) B_{c,p,i}(\theta).
  
where *s* runs over all signal templates in the current signal process group and *c_cp* denotes the coefficient for this channel and process template.


The uncertainty due to finite size of the simulated samples ("MC statistic uncertainty") can be taken
into account using the "Barlow-Beeston lite" method which defines one additional nuisance parameter with a Guassian distribution for each bin,
and performs the maximisation of the likelihood w.r.t. these new parameters analytically [Barlow1993]_, [Conway2011]_.


On a technical level, the mathematical model just introduced is represented by the python Model class.
Channels, processes and (nuisance) parameters are identified by strings: using the same string refers to the same channel/process/parameter (whether
a string is used to refer to a channel, a process, or a parameter is always clear from the context the string is used in).
A Model is usually created either by higgs_datacard.build_model or by build_model_from_rootfile.

The Model class contains all relevant information of the model, including the observed data, and all the predictions including their dependence on the
model parameters in the different channels, and which of the processes is to be considered as signal.

The Model class includes an instance of Distribution, model.distribution which is the prior distribution
for all nuisance parameters which is used at two places: (i) to draw random values for toy data generation, and (ii) as additional terms in the likelihood function.
Note that the parameter distribution can be overridden in many cases by method parameters, specifying independent Distributions for (i) and (ii).

It is possible to manipulate a Model object with many functions. Important examples are
 * add an additional log-normal rate uncertainty for a certain process which
   can be done with::
   
      model.add_lognormal_uncertainty('ttbar_rate', math.log(1.12), 'ttbar', '*')
      
   which adds a 12% log-normal uncertainty controlled by the uncertainty 'ttbar_rate' on the process called 'ttbar', correlated across all channels ('*').
 * combine two Models which can be done via::
 
      model1.combine(model2)
      
   which will add all channels of model2 to model1. In order for this to work correctly model1 and model2 must have been built using the same
   convention for the names of nuisance parameters. For shared nuisance parameters, the prior in model.distribution must be identical.

For more information about Model manipulation, see the documentation of the :ref:`Model` class.


The analysis.py script and the analysis workdir
===============================================

What is done and in which order is defined in the "analysis.py" script introduced above in the "Quickstart". You never execute this script directly, rather, you call
theta-auto.py and pass the name of the script as the argument to theta-auto.py. If you do not pass any argument to theta-auto.py, it assumes that the script name is "analysis.py".

On startup, theta-auto.py creates a "working directory" which has the same name as the analysis python script, but without the trailing ".py". The exact location
of the workdir is printed at the end of the execution of theta-auto.py. In this working directory,
theta-auto places intermediate results and will re-use them if possible. This is useful for faster turn-around: if you just want to change the way the result is displayed,
theta will not need to run again but the cached result from the previous execution are re-used, which can save a lot of time in some cases.

.. note::
  It makes sense to delete the analysis workdir from time to time, as it can grow very large. If you delete the workdir, you also delete the cache
  and the theta prorgam will run. See :ref:`distributed_running` for some details about the cache and workdir.

While you can choose the name of the script to execute (and hence also the name of the workdir), they are always refered to as
"the analysis.py script" and "the analysis workdir" throughout this documentation, respectively.


.. _stat_result:

Result of Statistical Methods
=============================

Different statistical methods are available, from maximum likelihood estimate, profile likelihood, CLs limits, p-value evaluation for discovering a signal, goodness of fit test with KS
or chi-square test statistic, and many more. All of these are accessible as python functions from analysis.py script. They return the result as return value of the
python method, so you can use it however you like (typically, you would just print it). Some function in addition also write results to a global object called "report".
Both are covered below.

.. _return_values:

Return values
-------------

The structure of the return value depends on the method and can be very different. That being said, some statistical methods perform very similar actions in that they
execute :program:`theta` per signal process group. In each execution, :program:`theta` will make ``n`` evaluations. For such methods, the return value is usually a nested python
dictionary for which the first-level key is the signal process id. The second-level key is highly method-dependent, but it usually refers to a certain aspect of the result. The
value is then a list of length ``n`` which contains the result of each toy.


.. warning:: The list of results can be shorter than ``n`` in some cases, e.g., if the minimization procedure did not converge for some inputs. The convention in this case is that this is only
   considered as an error (and a python ``RuntimeError`` will be thrown) if no result is available at all. Otherwise, the list of results has fewer than ``n`` entries. So you
   should not assume that the list of results as exactly ``n`` entries anywhere in your code.

   
.. _report:

Report object
-------------

As mentioned above, some methods do not just return a value, but they also write some summary into the ``report`` object. You
can get the content of this report object as html with this line in your analysis.py script::

   report.write_html('htmlout')

This should be done at the very end of the analysis.py script, as writing to the "report" object after it has been written is considered an error and will abort the execution
of the script.




.. [Barlow1993] Barlow, Roger J., Beeston, Christine, *Fitting using finite Monte Carlo samples*, Comput.Phys.Commun. **77**, 219-228, 1993.
.. [Conway2011] Conway, J. S., *Nuisance Parameters in Likelihoods for Multisource Spectra*, Proceedings of PHYSTAT 2011 Workshop on Statistical Issues Related to Discovery Claims in Search Experiments and Unfolding, 115-120, 2011

